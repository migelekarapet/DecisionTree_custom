# -*- coding: utf-8 -*-
"""Decision_Tree_EX.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/196VBs4TFH7xT59hv5iPKz3KNc74335fn
"""

from pandas.io.parsers.readers import read_csv
import pandas as pd
import numpy as np
from google.colab import files
import matplotlib.pyplot as plt
import matplotlib.image as pltimg
import plotly.graph_objects as go
import io
import math

from sklearn import tree
from sklearn.tree import DecisionTreeClassifier 
from sklearn.model_selection import train_test_split 
from sklearn.model_selection import cross_val_score
from sklearn import metrics 

from sklearn.tree import export_graphviz
import graphviz
from IPython.display import Image  
import pydotplus

#Import all required libraries. To calculate historical statistics and try to make predictions,
#about future movements we will create a trading strategy with different indicators.


# simple moving average
#the parameters of the SMA are df(which is our DataFrame; all the Apple data is in there; period - which is the period in which we will be calculating the SMA,
#and the inColName, outColName Which are names for the columns that we assign.
def sma(df, period, inColName, outColName): 
  inValues = df[inColName] # We define our InValues as the inColName of our DataFrame
  outValues = pd.Series( name=outColName, data=inValues.rolling(period).mean() ) # new series withthe outValues
  return outValues                                                               # Here we calculate the SMA of our stock



# exponential moving average which has the same parameters as our SMA.
def ema(df, period, inColName, outColName):
  numRows = df.shape[0] #We first add define numRow = df.shape[0] which will tell us the dimensions our our DataFrame at index 0
  inValues = df[inColName] #We then define our InValues as the inColName of our DataFrame

  outValues = pd.Series( name=outColName, index=range(numRows), dtype='float64') # Here we create a series with name, index.



  # first element; since it is recursive we need to start somewhere which is the first element , since there is no prev value we use the first element
  outValues[0] = inValues[0] # we equate the outValues at index[0] to the inValues at index[0]
  for i in range(1, numRows): #Need more understanding for the first element.
    outValues[i] = inValues[i] * (2/(1+period)) + outValues[i-1] * ( 1 - (2/(1+period)) ) #calculates value based on the prev value

  return outValues

# here we strat prepering to implement the RSi in our code
# example of rsi() call:
#   rsi(df, 5, 'Adj Close', 'rsi1')
def rsi(df, period, inColName, outColName): # define the rsi with 4 parameters
  df = df.copy() #copy the df 

  delta = df[inColName].diff(1) # the diff.() returns a DataFrame with the difference between the values for each row and, by default, the previous row
  gain = delta.clip(lower = 0) #values outside the interval are clipped to the interval edges. For example, if an interval of [0, 1] is specified, values smaller than 0 become 0, and values larger than 1 become 1
  loss = abs( delta.clip(upper = 0) ) #calculate our loss using clip() again, with an upper bound of 0
  
  ave_gain = pd.Series( name='ave_gain', index=range(len(gain)), dtype='float64') #new series, with name ave_gain. 
  ave_gain[period] = gain[:period + 1].rolling(period).mean() # defining the ave_gain to find the average gain in the period using the rolling() and mean() functions
  for i in range(period + 1, len(ave_gain)): #for loop, we use this to fill out our Series starting from 1: the range of our period + 1
    prev = ave_gain[i - 1] #the prev ave_gain is the [i] index in the ave_gain Series minus 1(the 1st prev == ave_gain[period] calculated above))
    val = gain[i]
    ave_gain[i] = (prev * (period - 1) + val)/period #finding the ave_gain 
  
  ave_loss = pd.Series( name='ave_loss', index=range(len(loss)), dtype='float64')# now we need the ave_loss, ere again we create a new Series
  ave_loss[period] = loss[:period + 1].rolling(period).mean() #defining the ave_loss to find the average gain in the period using the rolling() and mean() functions.
  for i in range(period + 1, len(ave_loss)):
    prev = ave_loss[i - 1]
    val = loss[i] # unlike FirstStrategy collab book, the 'loss' calculated here in 4th line of f-n() uses abs() - which plays same role as taking minus of negative value of loss in previous notebook
    ave_loss[i] = (prev * (period - 1) + val)/period 

  rs = ave_gain / ave_loss #we need to calc the relative strangth before we can calculate the rsi
  rsi = 100 - (100/(1 + rs))  #formula for the RSi 
  return rsi

# ATR shows investors the average range prices swing for an investment over a specified period
def atr(df, period, outColName): 
  #we calculate the Average True Range, the parameters that we need are the df, the periods in which we are computing the atr and the outColNames.
  high_close = np.abs(df['High'] - df['Adj Close'].shift()) # array operation shifting the ith value of  Adj Close by one (i.e. obtaining i-1 th)#to calculate the high close we subtract the the high values from the previous Adj Close values (is the shift called for that?), we need these numbers to be aboslute values so we add the abs() function
  low_close = np.abs(df['Low'] - df['Adj Close'].shift()) # the shift() function removes an item from the beginning of an array and shifts every other item to the previous index,
  high_low =  df['High'] - df["Low"]

  ranges = pd.concat([high_low, high_close, low_close], axis=1) #Concat function concatenates dataframes along rows or columns. We can think of it as stacking up multiple dataframes.
  true_range = np.max(ranges, axis=1) #max range for our atr

  atr = true_range.rolling(period).sum()/period # The ATR is then a moving average, generally using 14 days, of the 'true_range'
  return atr


# MACD can help gauge whether a security is overbought or oversold
# macd call example: macd(df, 5, 15, 9, 'Adj Close', 'macd')

def macd(df, nShort, nLong, nSignal, inColName, outColName): #define the Moving Average Convergence Divergence; the MACD shows the relationship between the two moving averages
#MACD triggers technical signals when the MACD line crosses above the signal line (to buy) or falls below it (to sell)
  emaShort = ema(df, nShort, inColName, 'ema_short') # define our first moving average as emaShort
  emaLong = ema(df, nLong, inColName, 'ema_long') # the second moving average as emaLong
  
  dfMacd = pd.DataFrame() # create the MACD dataFrame
  dfMacd[outColName] = emaShort - emaLong # look at definition
  # the 3rd parameter passed to ema() is 'macd'; the passed'nSignal' is eq. 9 in this case; in context of ema- it's the 'period' param.

  # the macd calculated above is smoothed by applying ema()
  dfMacd[outColName+'_sig'] = ema(dfMacd, nSignal, outColName, 'macd_sig') # this column  will have the ema with signals, The signal line

  # see comments in notepad
  dfMacd[outColName+'_histo'] = dfMacd[outColName] - dfMacd[outColName+'_sig'] #the _histo colunm equation
 
  return dfMacd # this will print a dataFrame, but we use the MACD as a graph to find the distance between the MACD and its signal line.
###########################################
# Money Flow Index attempt
# MFI is a technical oscillator that uses price and volume data for identifying overbought or oversold signals in an asset. 
# It can also be used to spot divergences which warn of a trend change in price. The oscillator moves between 0 and 100.

def mfi(df, period): #calculating the MFI using df and period as our parameters
  high = df["High"] # define the highs, lows, close, and volume
  low = df["Low"]
  close = df["Adj Close"]
  volume = df['Volume']

  tp = (high + low + close)/3 #the formula for typical price
  rmf = tp * volume # calculate raw money flow
  pos_mf = pd.Series(index = range(len(rmf)), dtype = "float64") # positive money flow, with range of the length of the rmf
  neg_mf = pd.Series(index = range(len(rmf)), dtype = "float64") # same for the negative money flow
  
  for i in range(1, len(rmf)): #create a for loop with the range from 1 to the length of the rmf
    pos_mf[i] = rmf[i] if tp[i] > tp[i -1] else 0
    neg_mf[i] = rmf[i] if tp[i] < tp[i -1] else 0
   
  
  

  pos_mf_sum = pos_mf.rolling(period).sum() # finding the sums of the positive and negative money flows
  neg_mf_sum = neg_mf.rolling(period).sum()

  

  mfr = pos_mf_sum / neg_mf_sum

  mfi = 100 - (100 / (1 + mfr)) # formula and calculations of MFI

  return mfi 



#a = [1, 2, 3, None, 4, 5]

#b = pd.Series(data = a).sum()
#print(b)
####################################
# Commodity Channel Index (CCI)
def cci(df, period):
  
  high = df["High"] #for the calculations we need to define the high,low,and close from our dataFrame
  low = df["Low"]
  close = df["Adj Close"]
  
  tp = (high + low + close)/3 # typical price formula
  ma_tp = tp.rolling(period).mean() # find the moving average of our typical prices, by using the rolling and mean functions
  md = (tp - ma_tp).abs().rolling(period).mean() # finding the mean deviation by taking the absolute values and in the same way as above finding the mean

  cci = (tp - tp.rolling(period).mean())/(0.015 * md) # fromula for our CCI, again using rolling() and mean() functions

  return cci # the CCI column measures the diff between the current price and the historical ave price
   


# generate base signals (version 1 - long / short)
def signals_v1(df, nShort, nLong, outColName): #define signals
  numRows = df.shape[0] # equate numRows to the first dimension of our array

  smaShort = sma(df, nShort, 'Adj Close', 'sma_short') # for our signals we will use the two moving averages
  smaLong = sma(df, nLong, 'Adj Close', 'sma_long')

  sigs = pd.Series( name=outColName, index=range(numRows), dtype='float64') #new series 

  for i in range(1, numRows): # fill the series in the range of 1 to numRows; done in full analogy with sma_signals() of First Strategy book
    if(smaShort[i-1] < smaLong[i-1] and smaShort[i] > smaLong[i]):  # crossing up
      sigs[i] = 1 # means buy signal
    elif(smaShort[i-1] > smaLong[i-1] and smaShort[i] < smaLong[i]):  # crossing down
      sigs[i] = -1 # sell signal ; close the pos

  return sigs #returns the series of signals

# generate base signals (version 2 - long / short)
def signals_v2(df, nShort, nLong, outColName): # version_1 focuses on the crossing points of the sma's, version_2 focuses on whether one is above or below the other, for that reason in version_2 we will have more trade signals
  numRows = df.shape[0]

  smaShort = sma(df, nShort, 'Adj Close', 'sma_short')
  smaLong = sma(df, nLong, 'Adj Close', 'sma_long')

  sigs = pd.Series( name=outColName, index=range(numRows), dtype='float64')

  for i in range(0, numRows):
    if(smaShort[i] > smaLong[i]):
      sigs[i] = 1 #
    elif(smaShort[i] < smaLong[i]):
      sigs[i] = -1

  return sigs #same this as the signals from the function above

# trade

# the value of startIndex was obtained based on manual experimental results. it is basically "finding" the 
# proper index of df that matches the period common to all of our features
#  trade_basic_signals(df, 40, 'sigs', factor_columns) is exmaple call
def trade_basic_signals(df, startIndex, sigColName, dataCols): # we create a new dataFrame here
  columns = ['dir', 'entry_date', 'entry_index', 'entry_price', 'exit_date', 
             'exit_index', 'exit_price', 'return'] #the colunm names of our new df
  columns = columns.append(dataCols)# add these columns to dataCols 

  dfTrades = pd.DataFrame(columns=columns) #
  numRows = df.shape[0]

  dates = df['Date'] #get the dates from the Date column
  prices = df['Adj Close'] #get the prices from the Adj Close column

  # df['sigs'] was obtained previously as an output of signals_v2(df, 5, 10, "sigs") call
  signals = df[sigColName] # sigColName formal parameter = 'sigs' in exmaple code above; we use sig_v2 which generates signals  based on 2 SMAs's interplay

  # open Position (if any)
  curPos = None #currently we are not trading
  for i in range(startIndex, numRows): # range is from the startIndex (which we will define later) to our numRows
    sig = signals[i] # Makes things simpler for later

    # new position entry
    if(sig == 1 and curPos == None): # if there's BUY signal generated and there's no trade - we fill our new long trading position
      curPos = { 
          'dir': sig,
          'entry_date': dates[i],
          'entry_index': i, 
          'entry_price': prices[i], 
          'exit_index': None, 
          'exit_price': None, 
          'return': None
      }

      for col in dataCols:
        curPos[col] = df[col][i] # the current position column is assigned the value of ith position of columns 'col' of our dataFrame

    # exit current position

    # if the trading position exists AND (either of following there's SELL signal generated and there's trade in place, OR if the position is 5 or more days old, then the trading position is getting closed

    # this's done to generate sufficient amount of trades: sometimes a situations like those following uptrend could occur which would result in lesser trades generated
    #this if() below is mutually exclusive with the one above second if() could serve as else for the 1st one - details review again

    # short is used here along with other auxiliary condition to close the position; we are not doing short trades here as opposed to 1st strategy notebook
    # this is long only strategy (for those who did not get it yet :)
    if(curPos != None and (sig == -1 or i-curPos['entry_index'] >= 5)): # above we were in a new position now we are exiting our current position
      curPos['exit_date'] = dates[i]
      curPos['exit_index'] = i
      curPos['exit_price'] = prices[i]
      curPos['return'] = curPos['exit_price'] / curPos['entry_price'] - 1 # fill the rest of the dataFrame

      dfTrades = dfTrades.append(curPos, ignore_index=True)
      curPos = None # we are not trading right now
  
  return dfTrades # when printed this it returns a dataFrame with all columns that we created above

# prepare data for decision tree 
def prepareDTreeData(dfTrades, dataCols): #prep a new df for our decision tree model
  numRows = dfTrades.shape[0] 
  allColumns = dataCols 
  df = pd.DataFrame(columns=allColumns, index=range(numRows)) # the df will have columns that we will define in the bottom
                                                              # our range will be the range of numRows
  for col in dataCols:
    for i in range(0, numRows):
      df.loc[i, col] = dfTrades[col][i] # equate the inedex of two dataFrames so we can properly calc everything. The dates have to match
      # dir  entry_date  entry_index  entry_price  exit_index  exit_price, everything is dropped, only feature_cols retained; 
# last column: if return > 0, value of predictor = 1, o/w 0
  for i in range(0, numRows):  
    df.loc[i, 'success'] = 'positive' if dfTrades['return'][i] >= 0 else 'negative' # negative or postive conditon for our tree

  return df
################################

def equity_curve(dfTrades): # create an equity curve with the data from our dfTrades (could be reduced to the train size )

# imaging there were 500 trades in year; X axis ranges 1:500; Y-axis - measures the equity
# however the time unit here is trades, sort of speaking
# for. ex. these 500 trades could  very well be not evenly distributed
  current_equity = 100 # at the begining of our trade we are at 100% equity
  num_trades = dfTrades.shape[0] # equate the indices to match the dates
  equity = pd.Series(name = "equity", index = range(num_trades + 1)) # new series
  equity[0] = current_equity # starting value of equity at [0] index is 100%

  for i in range(num_trades): # create for loop to fill our series
    r = dfTrades["return"][i] # r is the returns of dfTrades that matches indices ofour new series  that's why we also add [i] in the end
    current_equity = current_equity * (1 + r) # formula for the current equity + / - up or down
    equity[i + 1] = current_equity # i starts frm 0; we already have  equity[0] initialized; hence we've to continue from (i+1)th index

  #equity.plot()
  print("this is our series of equity returns", equity)
  return equity  # Will print a series of our equity returns



# in this function we want to convert our equity curve that uses dfTrades(number of trades) to using the dates of our trades.
# 1st make a new dataframe for our function, with date, equity, return, and position columns
# define our start date, our end date, we subtract 1 from the lenght of the exit date because our trading has not come to an end yet.
#
def convert_eq_daily(eq, df, dfTrades):

  eq_daily = pd.DataFrame({"date": pd.Series(dtype= "str"), "equity": pd.Series(dtype= "float32"), "return": pd.Series(dtype= "float32"), "position": pd.Series(dtype= "int32")})
  start_date = dfTrades["entry_date"][0] # from dfTrades datatable: first position of the start date from the "entry_date" column 
  end_date = dfTrades['exit_date'][len(dfTrades['exit_date']) - 1] # last date of the trade, we subtract 1 because we have not ended the trade yet
  start_index = df[df['Date'] == start_date].index[0] # from the dataFrame we extract the index of record for given 'date' that matches start_date (better described below)
  end_index = df[df['Date'] == end_date].index[0] # from the dataFrame we extract the index of record for given 'date' that matches end_date
  
  # 1st trade's entry date is start_date; last trade's exit date is end_date
  # [df['Date'] == start_date].index[0] - extracts that index of original df, whcih corresponds to the date of 1st trade as indicated by start_date
  # df['Date'] == end_date is done similarly

  equity = 100 
  current_trade_index = 0 # reiterate 
  is_open_pos = False  #  this means that in the beginning we are not trading
# end_index - matches last trade's exit index in the main df
# start_index - matches first trade's entry index in the main df
  for i in range(start_index, end_index + 1):
    price = df['Adj Close'][i]
    previous_price = df['Adj Close'][i - 1]

    # dfTrades contain info on trades happened (entry-/exit indices, respective prices , dir, etc). But we do not have the daily equity inbetween these trades
    # so the idea is to fix the entry date of a trade, then obtain the price info from main df() to account for daily prices change. this is what's done when calculating return and equity
    # also the o
    ret = None # return is 0 for the begining of every trade, and if we have no position)
    pos = 1 if is_open_pos == True else 0 # if we are in an open_pos (i.e. trading) then our postion is 1 (which means: yes we are trading), o/w 0
    
    if is_open_pos:
      # if open position is empty then the return = price/prev_price - 1 % change; and equity = equity * (1 + return) - and monitor equity change (if ret is minus - then down)
      ret = price/previous_price - 1
      equity = equity * (1 + ret)
      if i == dfTrades['exit_index'][current_trade_index]: # current_trade_index is which trade we're looking at
        is_open_pos = False
        current_trade_index += 1 # every time we close we go to the next row of trades afterwards
    # consider a case when a rtade is opened i is starting being iterated over
    # is_open_pos is indicating whether or not we're within a trade; let's considetr it is a case ; then the return and the equity figures are calculatred  for that date
    # i is incremented; as long as we're in the trade the figures above are calculated again; i is incremented; assume we hit the end of trade; then the "position" gets closed
    # 
    #thereafter two cases are possible ; i could be inbetween trades ; ret is == 0 for thsoe cases
    # if a new trade is detected upon incrementing i, then a new "position" is created

    else:
      # we do not have open positions here; today's equity equals the one from yesterday
      # this is why ret is 0
      ret = 0 
      if i == dfTrades['entry_index'][current_trade_index]:
        is_open_pos = True

    # no matter if we're within trade or no this record is created; for those days when no trade was initiated, the ret is obviously ==0, and the equity == the one from previous trading day (as indicated byexit index)
    eq_daily = eq_daily.append({
        'date': df['Date'][i],
        'equity': equity,
        'return': ret,
        'position': pos
    }, ignore_index = True)

  print("printing eq_daily")
  print(eq_daily)

    
  plt.figure(figsize=(10,5))
  eq_daily['equity'].plot()


  
  print(start_index)
  print(end_index)
  
  # the series from above that had our equity in terms of trades, when we convert this series in this function it becomes a dataFrame
  return eq_daily # a new dataFrame will be printed that has converted our prev data into daily data.

# we create a new dataframe to caputure both our equity curve and the becnhmark data, so we can calculate alpha,beta,sharpe ratio afterwards.
def prep_asset_data(equity, benchmark):# parameters are equity and benchmark; the names don't have to be the same because we call them at the bottom of our code.
  df = pd.DataFrame({"date": pd.Series(dtype= "str"), "equity": pd.Series(dtype= "float32"),
                     "benchmark": pd.Series(dtype= "float32")}) # new dataframe format with three columns date,eq,benchmark.
  start_date = equity["date"][0] # the start date of this df will equal to the start date of our equity at index[0]
  end_date = equity["date"][len(equity['date']) - 1] # define start and end indexes, end is the whole len of eq -1 b/c we did not reach the end yet.
  
  start_index = benchmark['Date'][benchmark['Date'] == start_date].index[0] #the start and end index are equal to the start&end date which we defined above.
  end_index = benchmark['Date'][benchmark['Date'] == end_date].index[0] #why do we write benchmark['Date']two times right beside eachother?? (b/c we want the indexes to equal the dates)

  for i in range(start_index, end_index + 1): # we need the end index to be inclusive that s why we add 1, start is inclusive the end is not hence +1!!
    date = benchmark['Date'][i] # in the for loop we start filling our dataframe
    p1 = benchmark['Adj Close'][i] #
    p0 = benchmark['Adj Close'][i - 1]
    r_benchmark = p1/p0 - 1 # calculate the return of the benchmark
    r_equity = equity['return'][i - start_index] # return of the equity; we do i - start_index 
    # b/c (i) is the start of our range, the dates of the benchmark and equity have to match for the comparison to work,
    # first i = 836 (which is the first point where the date of the benchmark matches the date of the equity) start_index= 836 but it doesn't change
    # as i increases to 837,894,1003, all the way to 1236. this way we are able to match the dates of the returns of both stocks.
    
    # the eq_daily is matching the last 30% (test data) ; we shift the benchmark df accordingly ( see [i - start_index]) and then place the matching pairs of eq_daily and benchmark returns side by side
    # we append(add) a library to our df to fill the data with all that we defined for this function above
    df = df.append({
        'date': date,
        'equity': r_equity,
        'benchmark': r_benchmark
      
    }, ignore_index = True) # if its not True it throws an error


  print(df)

  return df # new df will be printed that will have the required data to calculate the alpha, beta, and sharpe ratio of our stock
        
def beta(df2): # calc beta
  mean_APPLE = df2['equity'].mean() # finding the mean of the eq and the benchmark
  mean_SPY = df2['benchmark'].mean()

  #print(mean_SPY)
  #print(mean_APPLE)
  
  cov = df2['equity'].cov(df2['benchmark']) # following the formula for the beta we need to find the covariance of our equity and the variance of our benchmark
  var = df2['benchmark'].var()
  
  beta_ratio = cov/var
 
  print(cov)

  print('Beta is:', beta_ratio)
  return beta_ratio # will return the value of our beta
  

def alpha(df2):
  mean_APPLE = df2['equity'].mean() # finding the mean of our equity and benchmark
  mean_SPY = df2['benchmark'].mean()

  cov = df2['equity'].cov(df2['benchmark']) # again calculateing the variance and covariance
  var = df2['benchmark'].var()
  
  beta_ratio = cov/var #beta formula
  
  b = beta_ratio # make it cleaner so qe equate b to our beta_ratio
  market_ret = df2['benchmark'].mean() # finding the mean of our equity and benchmark i.e the average returns for equity and the bnchmark
  equity_ret = df2['equity'].mean()
  #risk_free_rate = 0.0 # for simplicity risk free rate we will equate to 0

  alpha_ratio = equity_ret - b*market_ret #formula for the alpha ratio

  print('Alpha is: ', alpha_ratio)

  return alpha_ratio # will print the alpha ratio


def sharpe(df2): # finding the sharpe ratio using the same df we did for the alpha and beta
  expected_eq_return = df2['equity'].mean() # finding the expected returns of our equity
  sd_eq_return = df2['equity'].std() # we also need to find the standard deviation of our equity
  #risk_free_rate = 0.0

  sharpe_ratio = expected_eq_return/sd_eq_return # formula for the sharpe ratio

  yearly_sharpe = sharpe_ratio * math.sqrt(252) # we only have 252 trading days in a year, so this calculation will be for the yearly sharpe ratio

  print("Sharpe Ratio is: ", sharpe_ratio)
  print(yearly_sharpe)

  return sharpe_ratio, yearly_sharpe # will return our sharpe ratio and our yearly sharpe



def drawdowns(equity_curve): # find the drawdowns of our equity  (not the daily one; the Trades one)
  l = len(equity_curve) # lenght is the len of the eq
  trough = pd.Series(name = "trough", index = range(l)) # creating a series of the Trough(min) values of our eq
  peak = pd.Series(name = "peak", index = range(l)) # creating a series of the Trough(max) values of our eq
  
  peak[0] = equity_curve[0] # both peak and trough are equal to the [0] index of our equity_curve
  trough[0] = equity_curve[0] 
  
  #initialization of values above
  for i in range(1, l): # filling our series that we created above
    v = equity_curve[i]
    if v > peak[i - 1]:
      peak[i] = v
      trough[i] = v # b/c the previous min should be voided
    elif v < trough[i -1]:
      peak[i] = peak[i - 1]
      trough[i] = v
    else:
      peak[i] = peak[i - 1]
      trough[i] = trough[i - 1]
      
  diff = (trough - peak) / peak # array operation - carried out for each cell 
  mdd = min(diff) # calculation of max draw down
  # New dataframe being created here for the drawdown table
  dd = pd.DataFrame({"start": pd.Series(dtype= "int32"), "end": pd.Series(dtype= "int32"), "len": pd.Series(dtype= "int32"), "dd": pd.Series(dtype= "int32")})
  
  current_dd = None

# when starts when ends, length and value of drawdown
  for i in range(len(diff)): # we fill our dataFrame here with colums [start,end,len,dd]
    v = diff[i] 
    if v < 0 and current_dd == None: # # if the current_dd flag is None means there's no drawdown, so we create on provided that diff[i] is negative
      current_dd = {
          "start" : i, 
          "end" : None,
          "len" : 0,
          "dd" : v
      }
    
    elif v < 0 and current_dd != None:
      current_dd["len"] += 1 # continuing downfall of drawdown, incrementing the corresponding cell value of 'len' column
      if v < current_dd["dd"]:
        current_dd['dd'] = v

    elif v == 0 and current_dd != None:
      current_dd["end"] = i
      current_dd["len"] += 1
      dd = dd.append(current_dd, ignore_index = True)
      current_dd = None #finishing current dd

  if current_dd != None: #at the end of for() loop, if current_dd is not empty we append it to dd dataframe and return
    #current_dd["end"] = len(diff) - 1
    dd = dd.append(current_dd, ignore_index = True)   

# below we calculate the average dd, the standard deveation of the drawdown, and drawdown lenghts and its SD.

  avg = dd["dd"].mean()
  
  med_dd = dd["dd"].median()

  sd_dd = dd["dd"].std()
  
  min_len = dd["len"].min()

  max_len = dd["len"].max()

  avg_dd_len = dd["len"].mean()

  sd_dd_len = dd["len"].std()

  med_dd_len = dd["len"].median()
  
  total_len = dd["len"].sum()
  
  plt.figure(figsize=(10,5))
  diff.plot()
  print(dd)
  #equity_curve.plot()
  #peak.plot()
  #trough.plot()
  return dd, mdd, avg, med_dd, sd_dd, min_len, max_len, avg_dd_len, med_dd_len, sd_dd_len,total_len



############################################ 
df = read_csv('AAPL.csv')
print(df)
dfSPY = read_csv('SPY.csv')
print(dfSPY)
df['rsi1'] = rsi(df, 5, 'Adj Close', 'rsi1')
df['rsi2'] = rsi(df, 15, 'Adj Close', 'rsi2')
df['atr1'] = atr(df, 7, 'atr1')
df['atr2'] = atr(df, 14, 'atr2')
#print(dfSPY)
dfMacd = macd(df, 5, 15, 9, 'Adj Close', 'macd')
df['macd_sig'] = dfMacd['macd_sig']
df['macd_histo'] = dfMacd['macd_histo']

df["mfi1"] = mfi(df, 5)
df["mfi2"] = mfi(df, 15)
df['cci'] = cci(df, 20)

factor_columns = ['rsi1', 'atr1', 'atr2', 'macd_sig', 'macd_histo', "mfi1", "cci"]
df['sigs'] = signals_v2(df, 5, 10, "sigs")


# returns the df of trades only (total 151 rows for current input); for reference - df, dfSPY had 1258 entries each
dfTrades = trade_basic_signals(df, 40, 'sigs', factor_columns)

# returns the trades df  reduced to 'factor_columns' and enhanced with predictor (positive/negative) depending on trade's return sign
# total 151 rows for current input
df1 = prepareDTreeData(dfTrades, factor_columns)

print("dfTrades - output of trade_basic_signals")
print(dfTrades)

print("df1 - output of prepareDTreeData")
print(df1)



#print("mdd", mdd)
# preparation step for splitting to independent and predictor variables
X = df1[factor_columns]
y = df1.success

print("The X is:", X)
print("The y is:", y)

n_trades = df1.shape[0]
train_size = int(n_trades * 0.7)
test_size = n_trades - train_size

X_train = X[:train_size]
y_train = y[:train_size]
X_test = X[train_size:]
y_test = y[train_size:]


t_test = dfTrades[train_size:] # last 30% of main df size
t_test.reset_index(inplace=True)

print("printing t_test - size is times 0.3 of n_trades")
print(t_test)
#equity_curve(t_test)

eq = equity_curve(t_test)
dd, mdd, avg, med_dd, sd_dd, min_len, max_len, avg_dd_len, med_dd_len, sd_dd_len, total_len = drawdowns(eq)


#print(mdd, avg, med_dd, sd_dd, min_len, max_len, avg_dd_len, med_dd_len, sd_dd_len, total_len)

plt.figure(figsize=(10,5))
eq.plot()

# list of parameters for convert_eq_daily()
# return value of equity_curve() , original df, t_test = dfTrades[train_size:] 
eq_daily = convert_eq_daily(eq, df, t_test)
df2 = prep_asset_data(eq_daily, dfSPY)
beta_val = beta(df2)
alpha_val = alpha(df2)
sharpe_val = sharpe(df2)
# print(n_trades, y_train.shape[0], y_test.shape[0])
# print(X_train)
# print(X_test)

###########################################################



#######################################################################
# function for fitting trees of various depths on the training data using cross-validation
def run_cross_validation_on_trees(X, y, tree_depths, cv=5, scoring='accuracy'):
    cv_scores_list = []
    cv_scores_std = []
    cv_scores_mean = []
    accuracy_scores = []
    for depth in tree_depths:
        tree_model = DecisionTreeClassifier(criterion='entropy', max_depth=depth)
        cv_scores = cross_val_score(tree_model, X, y, cv=cv, scoring=scoring)
        cv_scores_list.append(cv_scores)
        cv_scores_mean.append(cv_scores.mean())
        cv_scores_std.append(cv_scores.std())
        accuracy_scores.append(tree_model.fit(X, y).score(X, y))
    cv_scores_mean = np.array(cv_scores_mean)
    cv_scores_std = np.array(cv_scores_std)
    accuracy_scores = np.array(accuracy_scores)
    return cv_scores_mean, cv_scores_std, accuracy_scores

# function for plotting cross-validation results
def plot_cross_validation_on_trees(depths, cv_scores_mean, cv_scores_std, accuracy_scores, title):
    fig, ax = plt.subplots(1,1, figsize=(15,5))
    ax.plot(depths, cv_scores_mean, '-o', label='mean cross-validation accuracy', alpha=0.9)
    ax.fill_between(depths, cv_scores_mean-2*cv_scores_std, cv_scores_mean+2*cv_scores_std, alpha=0.2)
    ylim = plt.ylim()
    ax.plot(depths, accuracy_scores, '-*', label='train accuracy', alpha=0.9)
    ax.set_title(title, fontsize=16)
    ax.set_xlabel('Tree depth', fontsize=14)
    ax.set_ylabel('Accuracy', fontsize=14)
    ax.set_ylim(ylim)
    ax.set_xticks(depths)
    ax.legend()

sm_tree_depths = range(1,25)
sm_cv_scores_mean, sm_cv_scores_std, sm_accuracy_scores = run_cross_validation_on_trees(X_train, y_train, sm_tree_depths)
plot_cross_validation_on_trees(sm_tree_depths, sm_cv_scores_mean, sm_cv_scores_std, sm_accuracy_scores, 
                               'Accuracy per decision tree depth on training data')

idx_max = sm_cv_scores_mean.argmax()
sm_best_tree_depth = sm_tree_depths[idx_max]
sm_best_tree_cv_score = sm_cv_scores_mean[idx_max]
sm_best_tree_cv_score_std = sm_cv_scores_std[idx_max]
print('The depth-{} tree achieves the best mean cross-validation accuracy {} +/- {}% on training dataset'.format(
      sm_best_tree_depth, round(sm_best_tree_cv_score*100,5), round(sm_best_tree_cv_score_std*100, 5)))


#######################################################################
clf = DecisionTreeClassifier(criterion='entropy', max_depth= sm_best_tree_depth)
clf = clf.fit(X_train,y_train)

y_pred = clf.predict(X_train)
print("Train Accuracy:",metrics.accuracy_score(y_train, y_pred))

y_pred = clf.predict(X_test)
print("Test Accuracy:",metrics.accuracy_score(y_test, y_pred))


###################################
count_trades = len( dfTrades['return'][train_size:] )
total_profit = dfTrades['return'][train_size:].sum() * 100
success_rate = 0
for i in range(0, test_size):
  if dfTrades['return'][train_size+i] >= 0:
    success_rate += 1
success_rate = 100 * (success_rate / count_trades)
print('Basic - Total Return: {}%, Number of Trades: {}, Success Rate: {}%'.format(round(total_profit, 2), count_trades, round(success_rate, 2)))

count_trades = 0
total_profit = 0
success_rate = 0
for i in range(0, test_size):
  X = X_test[i:i+1]
  y = clf.predict(X)
  r = dfTrades[i+train_size:i+train_size+1]
  # print(X)
  # print(r['return'][i+train_size])
  # print(y[0])

  if(y[0] == 'positive'):
    total_profit += r['return'][i+train_size]
    count_trades += 1
    if r['return'][i+train_size] >= 0:
      success_rate += 1

success_rate = 100 * (success_rate / count_trades)
print('Optimized - Total Return: {}%, Number of Trades: {}, Success Rate: {}%'.format(round(total_profit*100, 2), count_trades, round(success_rate, 2)))


#####################################
class_names = ["negative", "positive"] #df1['success'].unique().tolist()
data = tree.export_graphviz(clf, out_file=None, feature_names=factor_columns, class_names=class_names, filled=True)
graph = graphviz.Source(data, format="png") 
graph